---
title: "\\vspace{-1.5cm} Performance of Classification MethodS in Pokemon Type Prediction "
author: |
  | Name1, Name2, Name3, Name4 -- University of Waterloo
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
output:
  bookdown::pdf_document2:
    toc: false
---

```{r setup, include = FALSE}
# Set of packages to use
require(kableExtra) # for tables
require(tidyverse) # loading it here prevents message display
require(nnet)
require(glmnet)
require(ggplot2)
require(leaps)
require(doParallel)
require(ggrepel)
require(tinytex)
require(scales)
require(reshape2)
library(Boruta)
library(gbm)
library(caret)
library(randomForest)
set.seed(441) # set the random seed for reproducible results

# Helper function reorder_cormat
reorder_cormat <- function(cormat){
  # Use correlation between variables as distance
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <-cormat[hc$order, hc$order]
}

# Helper function get_upper_tri
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
}
```

# Research Problem

Pokémon is one of the most popular games worldwide where players catch and train monsters known as Pokémon. As each Pokémon has its own types, it raises people’s interest in Pokémon type prediction based on other attributes of the Pokemon. However, many of the attempts failed as people have a limited number of observations due to game release or they limited the attributes used. In our study, we examine how prediction results change by including more Pokémon (including variants) up to Gen VIII and using a larger set of attributes. We also wish to evaluate the performance of different classification methods and are looking forward to predicting the second type of Pokémon.

# Dataset

We started with the [Pokédex Dataset](https://www.kaggle.com/datasets/mariotormo/complete-pokemon-dataset-updated-090420?select=pokedex_%28Update_04.21%29.csv), which contains one entry for each distinct Pokémon variant in generations 1-8 of the Pokémon games. It was primarily scraped from [Pokémon DB](https://pokemondb.net/pokedex/all), a website that lets users look up the attributes of any Pokémon. Attributes include generation number, height, combat statistics, training/breeding characteristics, and damage multipliers against each of the 18 types.
We created our own scrapers using the Python libraries `requests`, `beautifulsoup`, and `imageio` to fill in missing data and add further attributes about the sprites of each Pokemon. Further, we eliminate text features that have too many distinct values, or those which are too similar to what we are trying to predict. (Egg type is often exactly the same as type, so using it as a predictor would make the analysis uninteresting. After all transformations, our dataset contains 3 categorical features (including type), 1 binary feature, and 50 numerical features.

```{r,echo=F}
# Load and modify data
pokemon <- read.csv("C:/Users/Kkda/Desktop/Final Project/pokemon_train.csv",header=T)
pokemon[sapply(pokemon, is.character)] <- lapply(pokemon[sapply(pokemon, is.character)],as.factor)
# The numeric features
pokemon_numeric = pokemon[sapply(pokemon, is.numeric)]
```

# Exploratory Data Analysis
We briefly examine the average of numerical features of Pokemons in each type:
```{r,echo = F,fig.align='center',fig.dim=c(17,7)}
# Do the group means
pokemon_strength = pokemon_numeric[,20:37] # The weakness feature
classes = levels(pokemon$type_1)
n_feature = ncol(pokemon_strength)
pokemon_class_means = matrix(ncol=n_feature,nrow=18)
for (i in 1:18){
  pokemon_temp = pokemon_strength[pokemon$type_1 == classes[i],]
  pokemon_class_means[i,] = apply(pokemon_temp,2,mean)
}
rownames(pokemon_class_means) = classes
colnames(pokemon_class_means) = colnames(pokemon_strength)

df <- data.frame(melt(pokemon_class_means, id = c("feature","type")))
colnames(df) = c("type","feature","mean")

ggplot(df, aes(x = feature, y=mean, group=type))+
  geom_col(aes(fill=type),position = position_dodge2(reverse=T))+
  facet_wrap(.~feature,ncol=6,scales="free")+
  theme(legend.position="right")+
  labs(title='Average Pokemon Weakness Against Different Types')+
  theme(plot.title=element_text(hjust=0.5))+
  theme(plot.title=element_text(size=18))+
  scale_fill_manual(values=c("#A8B821", "#6F5848", "#7038F9","#F8D030", "#F7C9E3", 
                             "#C03028", "#F07F2F", "#A890ED", "#705798","#78C84F",
                             "#E0C069", "#98D8D8", "#A9A878", "#A040A1", 
                             "#F85788", "#B7A038", "#B8B8D0", "#6890F0"))
```
By inspection, the weakness of Pokemons varies greatly across different types. This provides a good indicator for __Decision Trees__ to split the data and makes it a good reference in evaluating the performance of other models.

# Overview of Classification Method

  - __Feature Elimination__: We determine the feature importance of the data using __Random Forest__, __Recursive Feature Elimination__ and the __Boruta algorithm__. This will reduce the feature space and avoid overfitting. More importantly, it gives a concise model for interpretation.
  
  - __Model fitting__: We fit different models using the selected features after the feature elimination. The models considered includes __Logistic Regression__, __Decision Tree__, __Random Forest__, __Neural Networks__ and __SVM__. The models will be fit using packages from __R__ and __Python__.

    From the __Exploratory Data Analysis__, we see the weakness of Pokemons varies greatly across different types. We believe this provides a good indicator for __Decision Trees__ to split the data, hence, making it a reasonable reference in evaluating the performance of other models.

```{r,echo = F,fig.align='center',fig.dim=c(14,5)}
# Random Forest for Variable Importance
# Removing 'type_2' 
pokemon_rf <- randomForest(type_1 ~., data = pokemon[,-5], importance = TRUE)

feat_imp <- importance(pokemon_rf) %>% 
  data.frame() %>% 
  mutate(feature = row.names(.)) 

ggplot(feat_imp, aes(x = reorder(feature, MeanDecreaseGini), 
                         y = MeanDecreaseGini)) +
    geom_bar(stat='identity', fill = "#1F6CFA") +
    coord_flip() +
    labs(
      x     = "Feature",
      y     = "Relative Importance",
      title = "Feature Importance From Random Forest"
    ) 
```

```{r}
# RFE loading from RDS file since takes too long to run
rfe_p <- readRDS("rfe_output.rds")
print(paste0('Eliminated Variable: ', setdiff(colnames(pokemon[,-c(4,5)]), rfe_p$optVariables)))
```

```{r}
# Boruta algorithm
b1 <- Boruta(pokemon[,-c(4,5)], pokemon[,4])
```

```{r}
# Display summary of b1
b1
```

From a collective standpoint, the features selected to be insignificant would be 'has_gender', 'sprite_overflow_horizontal', 'sprite_overflow_vertical', 'sprite_size'. In retrospect, the decisions make sense since has_gender is a TRUE/FALSE variable corresponding to whether a pokemon has a gender, from the game data very few pokemon are genderless so it would seem insignificant. The respective 'sprite' variables up for elimination are all based off the pokemon's sprite or pixel image in game, overflow relates to when the sprite is so big that it gets clipped off based off the general image format. Thus it would also make sense that these variables would not be very useful in trying to predict pokemon type since only physically massive pokemon would have this variable set to TRUE or 1. 


# Decision Tree
```{r}
# Build decision trees here
```
# Summary

# Appendix

